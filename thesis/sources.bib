
@article{deisenroth_gaussian_2015,
	title = {Gaussian processes for data-efficient learning in robotics and control},
	volume = {37},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6654139},
	pages = {408--423},
	number = {2},
	journaltitle = {Pattern Analysis and Machine Intelligence, {IEEE} Transactions on},
	author = {Deisenroth, Marc Peter and Fox, Dieter and Rasmussen, Carl Edward},
	urldate = {2016-02-01},
	date = {2015},
	file = {06654139.pdf:/home/markus/sync/zotero/storage/NTXRKWP9/06654139.pdf:application/pdf;Snapshot:/home/markus/sync/zotero/storage/RJFT85BV/articleDetails.html:text/html}
}

@article{rasmussen_gaussian_2006,
	title = {Gaussian processes for machine learning},
	url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.86.3414},
	author = {Rasmussen, Carl Edward},
	urldate = {2016-02-01},
	date = {2006},
	file = {Snapshot:/home/markus/sync/zotero/storage/Q9WU9NSU/summary.html:text/html}
}

@book{sutton_reinforcement_1998,
	title = {Reinforcement learning: An introduction},
	url = {https://books.google.de/books?id=CAFR6IBF4xYC},
	shorttitle = {Reinforcement learning},
	author = {Sutton, Richard S. and Barto, Andrew G.},
	urldate = {2016-02-01},
	date = {1998},
	file = {Snapshot:/home/markus/sync/zotero/storage/3IEI53VV/books.html:text/html}
}

@book{engelbrecht_fundamentals_2006,
	title = {Fundamentals of computational swarm intelligence},
	url = {http://dl.acm.org/citation.cfm?id=1199518},
	publisher = {John Wiley \& Sons},
	author = {Engelbrecht, Andries P.},
	urldate = {2016-02-01},
	date = {2006},
	file = {Snapshot:/home/markus/sync/zotero/storage/FSXKBSAR/citation.html:text/html}
}

@inproceedings{deisenroth_pilco:_2011,
	title = {{PILCO}: A model-based and data-efficient approach to policy search},
	url = {http://machinelearning.wustl.edu/mlpapers/paper_files/ICML2011Deisenroth_323.pdf},
	shorttitle = {{PILCO}},
	pages = {465--472},
	booktitle = {Proceedings of the 28th International Conference on machine learning ({ICML}-11)},
	author = {Deisenroth, Marc and Rasmussen, Carl E.},
	urldate = {2016-02-01},
	date = {2011},
	file = {[PDF] von wustl.edu:/home/markus/sync/zotero/storage/UCEUWK2U/Deisenroth and Rasmussen - 2011 - PILCO A model-based and data-efficient approach t.pdf:application/pdf}
}

@article{deisenroth_learning_2011,
	title = {Learning to Control a Low-Cost Manipulator using Data-Efficient Reinforcement Learning},
	url = {http://core.ac.uk/download/pdf/241164.pdf},
	author = {Deisenroth, Marc Peter and Rasmussen, Carl Edward and Fox, Dieter},
	urldate = {2016-02-01},
	date = {2011},
	file = {[PDF] von core.ac.uk:/home/markus/sync/zotero/storage/IH9TN5RX/Deisenroth et al. - Learning to Control a Low-Cost Manipulator using D.pdf:application/pdf}
}

@inproceedings{snelson_sparse_2005,
	title = {Sparse Gaussian processes using pseudo-inputs},
	url = {http://machinelearning.wustl.edu/mlpapers/paper_files/NIPS2005_543.pdf},
	pages = {1257--1264},
	booktitle = {Advances in neural information processing systems},
	author = {Snelson, Edward and Ghahramani, Zoubin},
	urldate = {2016-02-01},
	date = {2005},
	file = {[PDF] von wustl.edu:/home/markus/sync/zotero/storage/PDE2IBN3/Snelson and Ghahramani - 2005 - Sparse Gaussian processes using pseudo-inputs.pdf:application/pdf}
}

@thesis{snelson_flexible_2007,
	title = {Flexible and efficient Gaussian process models for machine learning},
	url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.62.4041},
	institution = {Citeseer},
	type = {phdthesis},
	author = {Snelson, Edward Lloyd},
	urldate = {2016-02-01},
	date = {2007},
	file = {[PDF] von psu.edu:/home/markus/sync/zotero/storage/3D3FKUK6/Snelson - 2007 - Flexible and efficient Gaussian process models for.pdf:application/pdf}
}

@thesis{damianou_deep_2015,
	title = {Deep Gaussian processes and variational propagation of uncertainty},
	url = {http://etheses.whiterose.ac.uk/id/eprint/9968},
	institution = {University of Sheffield},
	type = {phdthesis},
	author = {Damianou, Andreas},
	urldate = {2016-02-01},
	date = {2015},
	file = {[PDF] von whiterose.ac.uk:/home/markus/sync/zotero/storage/S8W2ZIJR/Damianou - 2015 - Deep Gaussian processes and variational propagatio.pdf:application/pdf;Snapshot:/home/markus/sync/zotero/storage/GTC5SWKF/9968.html:text/html}
}

@inproceedings{titsias_variational_2009,
	title = {Variational learning of inducing variables in sparse Gaussian processes},
	url = {http://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS09_Titsias.pdf},
	pages = {567--574},
	booktitle = {International Conference on Artificial Intelligence and Statistics},
	author = {Titsias, Michalis K.},
	urldate = {2016-02-01},
	date = {2009},
	file = {[PDF] von wustl.edu:/home/markus/sync/zotero/storage/ENE55SUP/Titsias - 2009 - Variational learning of inducing variables in spar.pdf:application/pdf}
}

@inproceedings{titsias_bayesian_2010,
	title = {Bayesian Gaussian process latent variable model},
	url = {http://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS2010_TitsiasL10.pdf},
	pages = {844--851},
	booktitle = {International Conference on Artificial Intelligence and Statistics},
	author = {Titsias, Michalis K. and Lawrence, Neil D.},
	urldate = {2016-02-01},
	date = {2010},
	file = {[PDF] von wustl.edu:/home/markus/sync/zotero/storage/XR3RNZW2/Titsias and Lawrence - 2010 - Bayesian Gaussian process latent variable model.pdf:application/pdf}
}

@article{brochu_tutorial_2010,
	title = {A Tutorial on Bayesian Optimization of Expensive Cost Functions, with Application to Active User Modeling and Hierarchical Reinforcement Learning},
	url = {http://arxiv.org/abs/1012.2599},
	abstract = {We present a tutorial on Bayesian optimization, a method of finding the maximum of expensive cost functions. Bayesian optimization employs the Bayesian technique of setting a prior over the objective function and combining it with evidence to get a posterior function. This permits a utility-based selection of the next observation to make on the objective function, which must take into account both exploration (sampling from areas of high uncertainty) and exploitation (sampling areas likely to offer improvement over the current best observation). We also present two detailed extensions of Bayesian optimization, with experiments---active user modelling with preferences, and hierarchical reinforcement learning---and a discussion of the pros and cons of Bayesian optimization based on our experiences.},
	journaltitle = {{arXiv}:1012.2599 [cs]},
	author = {Brochu, Eric and Cora, Vlad M. and de Freitas, Nando},
	urldate = {2016-02-01},
	date = {2010-12-12},
	eprinttype = {arxiv},
	eprint = {1012.2599},
	keywords = {Computer Science - Learning, G.1.6, G.3, I.2.6},
	file = {arXiv\:1012.2599 PDF:/home/markus/sync/zotero/storage/VIHCEABW/Brochu et al. - 2010 - A Tutorial on Bayesian Optimization of Expensive C.pdf:application/pdf;arXiv.org Snapshot:/home/markus/sync/zotero/storage/W3UT47IB/1012.html:text/html}
}

@inproceedings{randlov_learning_1998,
	title = {Learning to Drive a Bicycle Using Reinforcement Learning and Shaping.},
	volume = {98},
	url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.52.3038},
	pages = {463--471},
	booktitle = {{ICML}},
	publisher = {Citeseer},
	author = {Randløv, Jette and Alstrøm, Preben},
	urldate = {2016-04-15},
	date = {1998},
	file = {download:/home/markus/sync/zotero/storage/QRBGIB4D/download.pdf:application/pdf}
}

@article{petersen_matrix_2008,
	title = {The matrix cookbook},
	volume = {7},
	url = {http://www.cim.mcgill.ca/~dudek/417/Papers/matrixOperations.pdf},
	pages = {15},
	journaltitle = {Technical University of Denmark},
	author = {Petersen, Kaare Brandt and Pedersen, Michael Syskind and {others}},
	urldate = {2016-02-01},
	date = {2008},
	file = {imm3274.pdf:/home/markus/sync/zotero/storage/CA4343RM/imm3274.pdf:application/pdf}
}

@article{mcallister_data-efficient_2016,
	title = {Data-Efficient Reinforcement Learning in Continuous-State {POMDPs}},
	url = {http://arxiv.org/abs/1602.02523},
	journaltitle = {{arXiv}:1602.02523},
	author = {{McAllister}, Rowan and Rasmussen, Carl Edward},
	urldate = {2016-02-28},
	date = {2016},
	file = {[PDF] von arxiv.org:/home/markus/sync/zotero/storage/8AMCCZ6R/McAllister and Rasmussen - 2016 - Data-Efficient Reinforcement Learning in Continuou.pdf:application/pdf;Snapshot:/home/markus/sync/zotero/storage/EGW68SWZ/1602.html:text/html}
}

@book{press_numerical_2007,
	title = {Numerical Recipes 3rd Edition: The Art of Scientific Computing},
	isbn = {978-0-521-88068-8},
	shorttitle = {Numerical Recipes 3rd Edition},
	abstract = {Co-authored by four leading scientists from academia and industry, Numerical Recipes Third Edition starts with basic mathematics and computer science and proceeds to complete, working routines. Widely recognized as the most comprehensive, accessible and practical basis for scientific computing, this new edition incorporates more than 400 Numerical Recipes routines, many of them new or upgraded. The executable C++ code, now printed in color for easy reading, adopts an object-oriented style particularly suited to scientific applications. The whole book is presented in the informal, easy-to-read style that made earlier editions so popular. Please visit www.nr.com or www.cambridge.org/us/numericalrecipes for more details. More information concerning licenses is available at: www.nr.com/licenses New key features:  2 new chapters, 25 new sections, 25\% longer than Second Edition Thorough upgrades throughout the text Over 100 completely new routines and upgrades of many more. New Classification and Inference chapter, including Gaussian mixture models, {HMMs}, hierarchical clustering, Support Vector {MachinesNew} Computational Geometry chapter covers {KD} trees, quad- and octrees, Delaunay triangulation, and algorithms for lines, polygons, triangles, and spheres New sections include interior point methods for linear programming, Monte Carlo Markov Chains, spectral and pseudospectral methods for {PDEs}, and many new statistical distributions An expanded treatment of {ODEs} with completely new routines  Plus comprehensive coverage of  linear algebra, interpolation, special functions, random numbers, nonlinear sets of equations, optimization, eigensystems, Fourier methods and wavelets, statistical tests, {ODEs} and {PDEs}, integral equations, and inverse theory},
	pagetotal = {1195},
	publisher = {Cambridge University Press},
	author = {Press, William H.},
	date = {2007-09-06},
	langid = {english},
	keywords = {Computers / Mathematical \& Statistical Software, Mathematics / Applied, Mathematics / General, Mathematics / Numerical Analysis}
}

@thesis{deisenroth_efficient_2010,
	title = {Efficient Reinforcement Learning using Gaussian Processes},
	url = {http://www.cs.washington.edu/research/projects/aiweb/media/papers/tmppqidj5},
	institution = {{KIT} Scientific Publishing},
	type = {phdthesis},
	author = {Deisenroth, Marc Peter},
	urldate = {2016-04-19},
	date = {2010},
	file = {deisenroth.pdf:/home/markus/sync/zotero/storage/TNS29KIU/deisenroth.pdf:application/pdf;[HTML] von google.de:/home/markus/sync/zotero/storage/9T77GEEF/books.html:text/html}
}

@book{russell_artificial_2010,
	title = {Artificial Intelligence: A Modern Approach},
	isbn = {978-0-13-604259-4},
	shorttitle = {Artificial Intelligence},
	abstract = {Artificial Intelligence: A Modern Approach, 3e offers the most comprehensive, up-to-date introduction to the theory and practice of artificial intelligence. Number one in its field, this textbook is ideal for one or two-semester, undergraduate or graduate-level courses in Artificial Intelligence.   Dr. Peter Norvig, contributing Artificial Intelligence author and Professor Sebastian Thrun, a Pearson author are offering a free online course at Stanford University on artificial intelligence.    According to an article in  The New York Times , the course on artificial intelligence is “one of three being offered experimentally by the Stanford computer science department to extend technology knowledge and skills beyond this elite campus to the entire world.” One of the other two courses, an introduction to database software, is being taught by Pearson author Dr. Jennifer Widom.     Artificial Intelligence: A Modern Approach, 3e is available to purchase as an {eText} for your Kindle™, {NOOK}™, and the {iPhone}®/{iPad}®.    To learn more about the course on artificial intelligence, visit http://www.ai-class.com. To read the full New York Times article, click here.},
	pagetotal = {1153},
	publisher = {Prentice Hall},
	author = {Russell, Stuart Jonathan and Norvig, Peter},
	date = {2010},
	langid = {english},
	keywords = {Computers / Intelligence ({AI}) \& Semantics}
}

@book{murphy_machine_2012,
	title = {Machine Learning: A Probabilistic Perspective},
	isbn = {978-0-262-01802-9},
	shorttitle = {Machine Learning},
	abstract = {Today's Web-enabled deluge of electronic data calls for automated methods of data analysis. Machine learning provides these, developing methods that can automatically detect patterns in data and then use the uncovered patterns to predict future data. This textbook offers a comprehensive and self-contained introduction to the field of machine learning, based on a unified, probabilistic approach. The coverage combines breadth and depth, offering necessary background material on such topics as probability, optimization, and linear algebra as well as discussion of recent developments in the field, including conditional random fields, L1 regularization, and deep learning. The book is written in an informal, accessible style, complete with pseudo-code for the most important algorithms. All topics are copiously illustrated with color images and worked examples drawn from such application domains as biology, text processing, computer vision, and robotics. Rather than providing a cookbook of different heuristic methods, the book stresses a principled model-based approach, often using the language of graphical models to specify models in a concise and intuitive way. Almost all the models described have been implemented in a {MATLAB} software package -- {PMTK} (probabilistic modeling toolkit) -- that is freely available online. The book is suitable for upper-level undergraduates with an introductory-level college math background and beginning graduate students.},
	pagetotal = {1098},
	publisher = {{MIT} Press},
	author = {Murphy, Kevin P.},
	date = {2012-08-24},
	langid = {english},
	keywords = {Computers / Machine Theory}
}

@book{astrom_introduction_1971,
	title = {Introduction to Stochastic Control Theory},
	isbn = {978-0-08-095579-7},
	abstract = {In this book, we study theoretical and practical aspects of computing methods for mathematical modelling of nonlinear systems. A number of computing techniques are considered, such as methods of operator approximation with any given accuracy; operator interpolation techniques including a non-Lagrange interpolation; methods of system representation subject to constraints associated with concepts of causality, memory and stationarity; methods of system representation with an accuracy that is the best within a given class of models; methods of covariance matrix estimation;methods for low-rank matrix approximations; hybrid methods based on a combination of iterative procedures and best operator approximation; andmethods for information compression and filtering under condition that a filter model should satisfy restrictions associated with causality and different types of memory.As a result, the book represents a blend of new methods in general computational analysis,and specific, but also generic, techniques for study of systems theory ant its particularbranches, such as optimal filtering and information compression.- Best operator approximation,- Non-Lagrange interpolation,- Generic Karhunen-Loeve transform- Generalised low-rank matrix approximation- Optimal data compression- Optimal nonlinear filtering},
	pagetotal = {318},
	publisher = {Elsevier},
	author = {Åström, Karl J.},
	date = {1971-02-27},
	langid = {english},
	keywords = {Mathematics / Algebra / Linear, Mathematics / Calculus, Mathematics / Mathematical Analysis, Mathematics / Numerical Analysis, Technology \& Engineering / Mechanical}
}

@book{scholkopf_learning_2002,
	title = {Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond},
	isbn = {978-0-262-19475-4},
	shorttitle = {Learning with Kernels},
	abstract = {In the 1990s, a new type of learning algorithm was developed, based on results from statistical learning theory: the Support Vector Machine ({SVM}). This gave rise to a new class of theoretically elegant learning machines that use a central concept of {SVMs} -- -kernels--for a number of learning tasks. Kernel machines provide a modular framework that can be adapted to different tasks and domains by the choice of the kernel function and the base algorithm. They are replacing neural networks in a variety of fields, including engineering, information retrieval, and bioinformatics. Learning with Kernels provides an introduction to {SVMs} and related kernel methods. Although the book begins with the basics, it also includes the latest research. It provides all of the concepts necessary to enable a reader equipped with some basic mathematical knowledge to enter the world of machine learning using theoretically well-founded yet easy-to-use kernel algorithms and to understand and apply the powerful algorithms that have been developed over the last few years.},
	pagetotal = {658},
	publisher = {{MIT} Press},
	author = {Schölkopf, Bernhard and Smola, Alexander J.},
	date = {2002-01},
	langid = {english},
	keywords = {Computers / Intelligence ({AI}) \& Semantics, Computers / Programming / General}
}

@article{hein_reinforcement_2016,
	title = {Reinforcement Learning with Particle Swarm Optimization Policy ({PSO}-P) in Continuous State and Actionspaces},
	volume = {7},
	number = {3},
	author = {Hein, Daniel and Hentschel, Alexander and Runkler, Thomas and Udluft, Steffen},
	date = {2016-07},
	file = {Reinforcement Learning with Particle Swarm Optimization Policy.pdf:/home/markus/sync/zotero/storage/JHW8MFMJ/Reinforcement Learning with Particle Swarm Optimization Policy.pdf:application/pdf}
}

@inproceedings{eberhart_comparing_2000,
	title = {Comparing inertia weights and constriction factors in particle swarm optimization},
	volume = {1},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=870279},
	pages = {84--88},
	booktitle = {Evolutionary Computation, 2000. Proceedings of the 2000 Congress on},
	publisher = {{IEEE}},
	author = {Eberhart, Russ C. and Shi, Yuhui},
	urldate = {2016-05-13},
	date = {2000},
	file = {[PDF] von researchgate.net:/home/markus/sync/zotero/storage/DB2E6WRM/Eberhart and Shi - 2000 - Comparing inertia weights and constriction factors.pdf:application/pdf;Snapshot:/home/markus/sync/zotero/storage/3AKX79ES/login.html:text/html}
}

@article{ko_gp-bayesfilters:_2009,
	title = {{GP}-{BayesFilters}: Bayesian filtering using Gaussian process prediction and observation models},
	volume = {27},
	url = {http://link.springer.com/article/10.1007/s10514-009-9119-x},
	shorttitle = {{GP}-{BayesFilters}},
	pages = {75--90},
	number = {1},
	journaltitle = {Autonomous Robots},
	author = {Ko, Jonathan and Fox, Dieter},
	urldate = {2016-05-27},
	date = {2009},
	file = {[PDF] von washington.edu:/home/markus/sync/zotero/storage/CDMAB63M/Ko and Fox - 2009 - GP-BayesFilters Bayesian filtering using Gaussian.pdf:application/pdf;Snapshot:/home/markus/sync/zotero/storage/ARXV7GFE/s10514-009-9119-x.html:text/html}
}

@article{kutta_beitrag_1901,
	title = {Beitrag zur näherungweisen Integration totaler Differentialgleichungen},
	url = {http://www.citeulike.org/group/1448/article/813805},
	author = {Kutta, Wilhelm},
	urldate = {2016-05-20},
	date = {1901},
	file = {Snapshot:/home/markus/sync/zotero/storage/QNDJTABB/813805.html:text/html}
}

@inproceedings{mckinney_data_2010,
	title = {Data Structures for Statistical Computing in Python},
	url = {https://conference.scipy.org/proceedings/scipy2010/mckinney.html},
	pages = {51--56},
	author = {{McKinney}, Wes},
	urldate = {2016-05-20},
	date = {2010},
	file = {Full Text PDF:/home/markus/sync/zotero/storage/4W8NUEB6/McKinney - 2010 - Data Structures for Statistical Computing in Pytho.pdf:application/pdf}
}

@article{walt_numpy_2011,
	title = {The {NumPy} Array: A Structure for Efficient Numerical Computation},
	volume = {13},
	issn = {1521-9615},
	doi = {10.1109/MCSE.2011.37},
	shorttitle = {The {NumPy} Array},
	abstract = {In the Python world, {NumPy} arrays are the standard representation for numerical data and enable efficient implementation of numerical computations in a high-level language. As this effort shows, {NumPy} performance can be improved through three techniques: vectorizing calculations, avoiding copying data in memory, and minimizing operation counts.},
	pages = {22--30},
	number = {2},
	author = {Walt, S. van der and Colbert, S. C. and Varoquaux, G.},
	date = {2011-03},
	keywords = {Arrays, Computational efficiency, data structures, Finite element methods, high level language, high level languages, mathematics computing, numerical analysis, numerical computation, numerical computations, numerical data, {NumPy}, numpy array, Performance evaluation, programming libraries, Python, Python programming language, Resource management, scientific programming, Vector quantization},
	file = {IEEE Xplore Abstract Record:/home/markus/sync/zotero/storage/BMNKPGZ9/articleDetails.html:text/html}
}

@online{gpy_gpy:_2012,
	title = {{GPy}: A Gaussian process framework in python},
	url = {https://github.com/SheffieldML/GPy},
	shorttitle = {{GPy}},
	author = {{GPy}},
	urldate = {2016-05-20},
	date = {2012},
	file = {Snapshot:/home/markus/sync/zotero/storage/R5I9KPTU/GPy.html:text/html}
}

@book{van_rossum_python_1995,
	title = {Python reference manual},
	url = {http://ft-sipil.unila.ac.id/dbooks/Python%20Reference%20Manual.pdf},
	publisher = {Centrum voor Wiskunde en Informatica Amsterdam},
	author = {Van Rossum, Guido and Drake Jr, Fred L.},
	urldate = {2016-05-27},
	date = {1995},
	file = {[PDF] von unila.ac.id:/home/markus/sync/zotero/storage/KBTNSIRC/Van Rossum and Drake Jr - 1995 - Python reference manual.pdf:application/pdf}
}

@article{toussaint_technical_2009,
	title = {Technical Note: Computing moments of a truncated Gaussian for {EP} in high-dimensions},
	url = {https://pdfs.semanticscholar.org/b88d/9fd24040ac50743bdaebb0a52af6d098fee1.pdf},
	shorttitle = {Technical Note},
	author = {Toussaint, Marc},
	urldate = {2016-05-30},
	date = {2009},
	file = {Snapshot:/home/markus/sync/zotero/storage/AQZHM68V/pdf.html:text/html}
}

@book{herbrich_gaussian_2005,
	title = {On Gaussian expectation propagation},
	url = {http://131.107.65.14/pubs/74554/EP.pdf},
	publisher = {Technical report, Microsoft Research Cambridge, research. microsoft. com/pubs/74554/{EP}. pdf},
	author = {Herbrich, Ralf},
	urldate = {2016-05-30},
	date = {2005},
	file = {[PDF] von 131.107.65.14:/home/markus/sync/zotero/storage/NHEHPQ3M/Herbrich - 2005 - On Gaussian expectation propagation.pdf:application/pdf}
}

@article{depeweg_learning_2016,
	title = {Learning and Policy Search in Stochastic Dynamical Systems with Bayesian Neural Networks},
	url = {http://arxiv.org/abs/1605.07127},
	abstract = {We present an algorithm for model-based reinforcement learning that combines Bayesian neural networks ({BNNs}) with random roll-outs and stochastic optimization for policy learning. The {BNNs} are trained by minimizing alpha-divergences, allowing us to capture complicated statistical patterns in the transition dynamics, e.g. multi-modality and heteroskedasticity, which are usually missed by other common modeling approaches. We illustrate the performance of our method by solving a challenging benchmark where model-based approaches usually fail and by obtaining promising results in a real-world scenario for controlling a gas turbine.},
	journaltitle = {{arXiv}:1605.07127 [cs, stat]},
	author = {Depeweg, Stefan and Hernández-Lobato, José Miguel and Doshi-Velez, Finale and Udluft, Steffen},
	urldate = {2016-06-06},
	date = {2016-05-23},
	eprinttype = {arxiv},
	eprint = {1605.07127},
	keywords = {Computer Science - Learning, Statistics - Machine Learning},
	file = {arXiv\:1605.07127 PDF:/home/markus/sync/zotero/storage/DR3EHNSK/Depeweg et al. - 2016 - Learning and Policy Search in Stochastic Dynamical.pdf:application/pdf;arXiv.org Snapshot:/home/markus/sync/zotero/storage/KU7W8W93/1605.html:text/html}
}

@article{stevens_holoviews:_2010,
	title = {{HoloViews}: Building Complex Visualizations Easily for Reproducible Science},
	url = {http://homepages.inf.ed.ac.uk/jbednar/papers/stevens.scipy15_draft.pdf},
	shorttitle = {{HoloViews}},
	author = {Stevens, Jean-Luc R. and Rudiger, Philipp and Bednar, James A.},
	urldate = {2016-06-06},
	date = {2010},
	file = {[PDF] von ed.ac.uk:/home/markus/sync/zotero/storage/3JHF3KG5/Stevens et al. - 2010 - HoloViews Building Complex Visualizations Easily .pdf:application/pdf}
}

@book{gauss_theoria_1809,
	title = {Theoria motus corporum coelestium in sectionibus conicis solem ambientium},
	url = {https://books.google.de/books?id=VKhu8yPcat8C},
	publisher = {sumtibus Frid. Perthes et {IH} Besser},
	author = {Gauss, Carl Friedrich},
	urldate = {2016-06-06},
	date = {1809},
	file = {[HTML] von google.de:/home/markus/sync/zotero/storage/5VVH3NXS/books.html:text/html}
}

@article{silver_mastering_2016,
	title = {Mastering the game of Go with deep neural networks and tree search},
	volume = {529},
	rights = {© 2016 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {0028-0836},
	url = {http://www.nature.com.eaccess.ub.tum.de/nature/journal/v529/n7587/full/nature16961.html},
	doi = {10.1038/nature16961},
	abstract = {The game of Go has long been viewed as the most challenging of classic games for artificial intelligence owing to its enormous search space and the difficulty of evaluating board positions and moves. Here we introduce a new approach to computer Go that uses ‘value networks’ to evaluate board positions and ‘policy networks’ to select moves. These deep neural networks are trained by a novel combination of supervised learning from human expert games, and reinforcement learning from games of self-play. Without any lookahead search, the neural networks play Go at the level of state-of-the-art Monte Carlo tree search programs that simulate thousands of random games of self-play. We also introduce a new search algorithm that combines Monte Carlo simulation with value and policy networks. Using this search algorithm, our program {AlphaGo} achieved a 99.8\% winning rate against other Go programs, and defeated the human European Go champion by 5 games to 0. This is the first time that a computer program has defeated a human professional player in the full-sized game of Go, a feat previously thought to be at least a decade away.},
	pages = {484--489},
	number = {7587},
	journaltitle = {Nature},
	shortjournal = {Nature},
	author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
	urldate = {2016-06-07},
	date = {2016-01-28},
	langid = {english},
	keywords = {Computational science, Computer science, Reward},
	file = {Full Text PDF:/home/markus/sync/zotero/storage/TNMQ8TSN/Silver et al. - 2016 - Mastering the game of Go with deep neural networks.pdf:application/pdf;Snapshot:/home/markus/sync/zotero/storage/IBIRXXFA/nature16961.html:text/html}
}

@inproceedings{kolter_probabilistic_2010,
	title = {A Probabilistic Approach to Mixed Open-loop and Closed-loop Control, with Application to Extreme Autonomous Driving},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5509562},
	pages = {839--845},
	booktitle = {Robotics and Automation ({ICRA}), 2010 {IEEE} International Conference on},
	publisher = {{IEEE}},
	author = {Kolter, J. Zico and Plagemann, Christian and Jackson, David T. and Ng, Andrew Y. and Thrun, Sebastian},
	urldate = {2016-06-07},
	date = {2010},
	file = {[PDF] von plagemann.net:/home/markus/sync/zotero/storage/T44Z7V43/Kolter et al. - A Probabilistic Approach to Mixed Open-loop and Cl.pdf:application/pdf;Snapshot:/home/markus/sync/zotero/storage/U2QP2Z8U/login.html:text/html}
}

@book{hsu_behind_2002,
	title = {Behind Deep Blue: Building the computer that defeated the world chess champion},
	url = {https://books.google.de/books?id=zV0W4729UqkC},
	shorttitle = {Behind Deep Blue},
	publisher = {Princeton University Press},
	author = {Hsu, Feng-Hsiung},
	urldate = {2016-06-07},
	date = {2002},
	file = {Snapshot:/home/markus/sync/zotero/storage/D767X76Z/books.html:text/html}
}