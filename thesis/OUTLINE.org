* Introduction
  - Rather philosophical
  - Machine Learning, Machine Intelligence
  - Why do we have uncertainties? Why are they important?
  - Current examples (AlphaGo?)

* Theory
** Reinforcement Learning
*** Problem statement
   - Agent and environment
   - Similarities to "traditional" controllers
   - States and Actions
   - Markov-Property of the state
   - Reward functions
   - Return and Value functions
   - Online vs. Offline
*** Model-Based Reinforcement Learning
   - Interaction vs. Simulation
   - Interaction is expensive but makes the model better
   - Use uncertainties to reduce model bias
   - Three layers
     + Learning the dynamics (GP)
     + Long-Term Predictions (Linearization)
     + Policy Optimization (not here) or Model Predictive Control (PSO)
   - We use uncertainties in all three
** Gaussian Processes
*** Definition
    - Gaussian processes as Stochastic processes
    - Every subset of which is Gaussian
    - Distribution over functions rather than vectors
*** Kernel functions
    - General properties
    - RBF as an example
    - Matern, Neural Network?
*** Regression with GPs
    - Predictive posterior
    - Marginal likelihood for finding hyperparameters
*** Sparse Approximations (SPGP)
    - Inverting K_NN is expensive
    - Approximate in smaller subspace
    - Formulation of SPGP
    - Interpretation as GP with specific Kernel function
    - Derive the likelihood?
    - Implementation??
    - Mention variational approaches
*** Linearization as a way to propagate uncertainties through time
    - GPs (or some oder model) give posterior uncertainties
    - But only for single points
    - How to get a posterior distribution given a prior one?
    - Maybe mention moment matching?
** PSO
*** Non-Linear optimization problems
    - Problem statement
    - Brief overview over approaches
      + Gradient-Based
      + Hessian-Based
      + Gradient-Free
*** PSO is Gradient-Free
    - Positions, Velocities
    - Neighborhoods
    - Update-Step
    - Velocity clamping
    - Values for omega and gammas

* Experiments
** Definition of the Bicycle Benchmark
   - State variables
   - Dynamics
   - Actions
   - Boundaries
   - Derivatives
** Modelling of the Bicycle Benchmark
   - GP Models
     + Model the deltas
     + One model per dimension
     + Implicit assumption that outputs are independent
   - Reward function
     + Definition without uncertainties
     + Extension with probabilities
     + "Stop Probabilities" and Bimodality
     + Extension of PILCO, truncated gaussians
** Results
   - Data Sets
     + Random exploration
     + Random sampling
     + Size of data sets
   - Technical choices
     + Values for N, M, Kernel in GPs
     + PSO parameters
   - Evaluation loop
     + Create data set
     + Train models
     + ~15 PSO runs
   - Mean-Mean Reward over multiple runs
   - Some interesting single trajectories

* Conclusion
  - Using uncertainties seems to help
  - But does not combine so well with PSO
  - Can we do better with closed policies?
